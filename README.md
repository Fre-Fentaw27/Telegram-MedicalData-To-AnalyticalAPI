# Telegram-MedicalData-To-AnalyticalAPI

An end-to-end data pipeline for Telegram, leveraging dbt for transformation, Dagster for orchestration, and YOLOv8 for data enrichment.

# Task 0: Project Setup & Environment Management

## ğŸ“¦ Prerequisites

- Python 3.8+
- PostgreSQL 13+
- pgAdmin 4
- Git

## ğŸ› ï¸ Setup Instructions

## Clone the repository

- git clone https://github.com/yourusername/Telegram-MedicalData-To-AnalyticalAPI.git
- cd Telegram-MedicalData-To-AnalyticalAPI

## Create and activate virtual environment

- python -m venv .venv
- source .venv/bin/activate # Linux/Mac
- .\.venv\Scripts\activate # Windows

## Install Python dependencies

- pip install -r requirements.txt

# Set up PostgreSQL

# Configure environment variables (.env file)

# Task 1: Data Scraping and Collection (Extract & Load)

### ğŸ“‹ Data Sources

Telegram channels:

- @CheMed123
- @lobelia4cosmetics
- @tikvahpharma

## ğŸ“‚ Project Structure

data/
â”œâ”€â”€ raw/ # Raw JSON files
â”‚ â””â”€â”€ telegram_messages/
â”‚ â”œâ”€â”€ 2022-09-05/
â”‚ â”‚ â””â”€â”€ CheMed123.json
â”‚ â””â”€â”€ 2025-05-20/
â”‚ â””â”€â”€ lobelia4cosmetics.json
â””â”€â”€ processed/ # Cleaned data
src/
â”œâ”€â”€ scraping/
â”‚ â”œâ”€â”€ telegram_scraper.py
â”‚ â””â”€â”€ data_loader.py
â””â”€â”€ load_to_postgres.py

## ğŸ”§ Key Components

- Telegram Scraper (telegram_scraper.py)

## ğŸš€ Execution Flow

## Run the scraper (saves to JSON)

- python src/scraping/telegram_scraper.py

## ğŸ“Š Sample Output

Loaded 76 messages from data/raw/telegram_messages/2022-09-05/CheMed123.json
Loaded 1000 messages from data/raw/telegram_messages/2025-05-20/lobelia4cosmetics.json

# Task 2: Data Modeling and Transformation (Transform)

# Medical Analytics Data Transformation (dbt Project)

## ğŸ“Œ Project Overview

This dbt project transforms raw Telegram medical channel messages from JSON files into an analytics-ready star schema in PostgreSQL. It serves as the "data transformation" layer between raw data and analytics/BI tools.

## ğŸ› ï¸ Technical Stack

- **Database**: PostgreSQL
- **Transformation**: dbt (data build tool)
- **Data Sources**: JSON files scraped from Telegram channels
- **Schemas**:
  - `raw`: Original ingested data
  - `staging`: Cleaned source data
  - `analytics`: Dimensional model

## ğŸ“‚ Project Structure

medical_analytics/
â”œâ”€â”€ dbt_project.yml # Project configuration
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ staging/ # Staging models
â”‚ â”‚ â”œâ”€â”€ stg_telegram_messages.sql
â”‚ â”‚ â””â”€â”€ schema.yml # Tests & docs
â”‚ â””â”€â”€ marts/
â”‚ â”œâ”€â”€ core/ # Dimensional models
â”‚ â”‚ â”œâ”€â”€ dim_channels.sql
â”‚ â”‚ â”œâ”€â”€ dim_dates.sql
â”‚ â”‚ â”œâ”€â”€ fct_messages.sql
â”‚ â””â”€â”€ schema.yml
â”œâ”€â”€ tests/
â”‚ â””â”€â”€ custom_data_tests/ # Custom data quality tests
â”œâ”€â”€ macros/ # Reusable SQL code
â””â”€â”€ packages.yml # dbt dependencies

## ğŸ”„ Data Flow

1. **Raw Data**: JSON files â†’ `raw.telegram_messages`
2. **Staging**:
   - Cleans raw data
   - Standardizes fields
   - Light transformations
   - Output: `staging.stg_telegram_messages`
3. **Marts**:
   - `dim_channels`: Channel metadata
   - `dim_dates`: Time dimensions
   - `fct_messages`: Message facts with foreign keys

## ğŸ§ª Data Quality Tests

## Custom Tests

ğŸš€ How to Run
Install dependencies:

- dbt deps
  Run transformations:
- dbt run
  Run tests:
- dbt test
  Generate docs:
- dbt docs generate
- dbt docs serve

## ğŸ› ï¸ Common Operations

Command Description

- dbt run --select staging(Run only staging models)
- dbt test --select stg_telegram_messages (Test only staging)
- dbt run --exclude dim_dates (Run all except dim_dates)

## Data Flow Diagram

![Data Transformation Flow](images/image.png)

## ğŸ§ª Data Quality Tests

### Automated Tests

```yaml
# Example from schema.yml
columns:
  - name: message_id
    tests:
      - unique
      - not_null
  - name: message_date
    tests:
      - not_null
```
